library(tidyverse)
library(anytime)
library(Hmisc)
library(tidymodels)


nasa <- read_csv("/Users/Jack/Documents/data.csv")

nasa_edu_net<-nasa[c(grep(".edu$", nasa$host), grep(".net$", nasa$host)),]

nasa_edu <-
  data.frame(grep(".edu$", nasa_edu_net$host), rep("edu", length(grep(".edu$", nasa_edu_net$host))))

nasa_net <-
  data.frame(grep("net$", nasa_edu_net$host), rep("net", length(grep("net$", nasa_edu_net$host))))

colnames(nasa_edu) <- c("index", "site_type")
colnames(nasa_net) <- c("index", "site_type")

edu_net_sites <- bind_rows(nasa_edu, nasa_net)

edu_net_sites <- edu_net_sites %>%
  arrange(index)

nasa_edu_net <-
  data.frame(nasa_edu_net, edu_net_sites[,2])

nasa_edu_net <- 
  nasa_edu_net %>%
  mutate(time = anytime(time)) %>%
  mutate(day = weekdays(as.Date(time))) %>%
  mutate(date = as.Date(time)) %>%
  select(-X1) %>%
  mutate(time = strftime(time, "%H:%M:%S"))

nasa_edu_net$response<-
  recode(nasa_edu_net$response, "200" = "ok", "302" = "found", "304" = "not-modified", "404" = "not-found")

colnames(nasa_edu_net)[7] <- "site_type"

nasa_edu_net <- nasa_edu_net[,c("host", "bytes", "date", "time", "day", "url", "method", "response", "site_type")]

nasa_edu_net<- nasa_edu_net %>%
  mutate(url_type = 
           ifelse(grepl(".gif$", nasa_edu_net$url), "gif", 
                  ifelse(grepl(".html$", nasa_edu_net$url), "html", 
                         ifelse(grepl(".jpg$", nasa_edu_net$url), "jpg",
                                ifelse(grepl(".jpeg$", nasa_edu_net$url), "jpg",
                                    ifelse(grepl(".mpg$", nasa_edu_net$url), "mpg", 
                                         ifelse(grepl(".xbm$", nasa_edu_net$url), "xbm", 
                                                ifelse(grepl(".GIF$", nasa_edu_net$url), "gif",
                                                       ifelse(grepl(".pl$", nasa_edu_net$url), "pl", 
                                                              ifelse(grepl(".txt$", nasa_edu_net$url), "txt", 
                                                                     ifelse(grepl(".wav$", nasa_edu_net$url), "wav", "other"))))))))))) 
nasa_edu_net<-nasa_edu_net %>%
  mutate(url_type = as.factor(url_type))

nasa_edu_net %>% 
  ggplot(aes(site_type)) +
  geom_bar() +
  facet_grid(day~url_type)


# Modified dataset --------------------------------------------------------

nasa_edu_net_filtered <- nasa_edu_net %>%
  select(-method, -url, - response)

nasa_edu_net_filtered$time<-as.numeric(substr(nasa_edu_net_filtered$time,1, nchar(nasa_edu_net_filtered$time)-6))

nasa_edu_net_filtered$date<-format(as.Date(nasa_edu_net_filtered$date), "%j")

nasa_edu_net_filtered <- nasa_edu_net_filtered %>%
  mutate(date = as.numeric(date), 
         day = as.factor(day))

# Plots -------------------------------------------------------------------

nasa_edu_net_filtered %>% 
  group_by(time) %>% 
  summarise(total_bytes = sum(bytes)) %>%
  ggplot(aes(time, total_bytes)) +
  geom_line()

nasa_edu_net_filtered %>% ggplot(aes(time, fill = site_type)) +
  geom_histogram(bins=23) +
  facet_grid(~site_type) +
  ggtitle("Time of Request, Faceted by Site Type")

nasa_edu_net_filtered %>% ggplot(aes(day)) +
  geom_bar() +
  facet_grid(~site_type) +
  ggtitle("Day of Request, Faceted by Site Type")

nasa_edu_net_filtered %>% ggplot(aes(response)) +
  geom_bar() +
  facet_grid(~site_type) +
  ggtitle("Response of Request, Faceted by Site Type")

nasa_edu_net_filtered %>% ggplot(aes(bytes)) +
  geom_histogram() +
  facet_grid(~site_type) +
  ggtitle("Amount of Bytes of Request, Faceted by Site Type")

nasa_edu_net_filtered %>% ggplot(aes(date, fill = site_type)) +
  geom_histogram() +
  facet_grid(~site_type) +
  ggtitle("Date of Request, Faceted by Site Type")


# Making high quality smaller dataset -------------------------------------

set.seed(1423)
fiveK_host_names<-
  training(
    initial_split(
      nasa_edu_net_filtered, 
      prop = 0.01, 
      strata = site_type)) %>%
  count(host)

nasa_edu_net_fiveK<-merge(fiveK_host_names, nasa_edu_net_filtered, by="host") 

nasa_edu_net_fiveK <-
  nasa_edu_net_fiveK %>%
  select(-n)

nasa_edu_net_fiveK<-
  nasa_edu_net_fiveK %>%
  count(host) %>%
  filter(n<10)

nasa_edu_net_fiveK<-merge(nasa_edu_net_fiveK, nasa_edu_net_filtered, by="host") 

nasa_edu_net_fiveK<-
  nasa_edu_net_fiveK %>%
  select(-n) 

nasa_edu_net_fiveK %>%
  count(host)

nasa_edu_net_fiveK<-read_csv("/Users/Jack/Documents/GitHub/Log-Data-Feature-Gen/input-automata-csv/small-nasa-edu-net-fiveK.csv")

#Adding url type

nasa_edu_net_fiveK_url<-semi_join(nasa_edu_net, nasa_edu_net_fiveK, by = "host") %>%
  select(host, bytes, date, time, day, url_type, site_type) %>%
  mutate(date = as.numeric(format(as.Date(date), "%j")), 
         time = as.numeric(substr(time,1, nchar(time)-6)),
         day = as.factor(day)) 
  

# Writing to csv ----------------------------------------------------------


write.csv(nasa_edu_net_filtered[,c(1:5)], "/Users/Jack/Documents/GitHub/Log-Data-Feature-Gen/input-automata-csv/nasa-edu-net.csv", row.names = FALSE)
write.csv(small_nasa_edu_net[,c(1:5)], "/Users/Jack/Documents/GitHub/Log-Data-Feature-Gen/input-automata-csv/small-nasa-edu-net.csv", row.names = FALSE)
write.csv(nasa_edu_net_fiveK[,c(1:5)], "/Users/Jack/Documents/GitHub/Log-Data-Feature-Gen/input-automata-csv/small-nasa-edu-net-fiveK.csv", row.names = FALSE)
write.csv(nasa_edu_net_fiveK_url[,c(1:6)], "/Users/Jack/Documents/GitHub/Log-Data-Feature-Gen/input-automata-csv/small-nasa-edu-net-fiveK_withURL.csv", row.names = FALSE)

